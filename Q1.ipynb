{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bTYoce2P23qD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming our main memory is big enough to hold all weights, inputs, and outputs\n",
        "def load_main_memory(main_memory, input_data, weights_data, mem_write):\n",
        "# This functions loads the initial weights and inputs to main memory"
        "  k = 0\n",
        "  for i in range(weights_data.size(0)): # Store weights first\n",
        "    main_memory[i] = weights_data[i]\n",
        "    mem_write += 1 # Count mem writes\n",
        "    k += 1\n",
        "\n",
        "  for i in range(k, input_data.size(0)+k): # Store inputs\n",
        "    main_memory[i] = input_data[i-k]\n",
        "    mem_write += 1 # Count mem writes\n",
        "\n",
        "  return main_memory, input_data.size(0)+k\n",
        "\n",
        "def load_buffer(main_memory, buffer, buf_row, frm_mem, which_data, len_weights, len_input, mem_read, buf_write):\n",
        "  # Check if buffer is full\n",
        "  if buf_row == buffer.size(0):\n",
        "    print(\"Buffer is full\")\n",
        "  else:\n",
        "  # Load the buffer\n",
        "    if which_data == \"ws\": # Load to buffer\n",
        "      for i in range(0, len_weights):\n",
        "        buffer[i] = main_memory[frm_mem]\n",
        "        mem_read += 1 # Read from mem\n",
        "        buf_write += 1 # Write buffer\n",
        "        frm_mem += 1\n",
        "        if i == buffer.size(0)-1:\n",
        "          break\n",
        "\n",
        "    elif which_data == \"os\": # Load inputs to buffer\n",
        "      for i in range(0, len_input):\n",
        "        print(i)\n",
        "        buffer[i] = main_memory[frm_mem]\n",
        "        mem_read += 1 # Read from mem\n",
        "        buf_write += 1 # Write buffer\n",
        "        frm_mem += 1\n",
        "        if i == buffer.size(0)-1:\n",
        "          break\n",
        "\n",
        "    else:\n",
        "      print(\"Invalid data type\")\n",
        "\n",
        "  return buffer, i"
      ],
      "metadata": {
        "id": "l0TkLFhL29kC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convolution(main_memory, mem_ptr, buffer, len_weights_flat, M, R, P, mem_read, mem_write, buf_read, buf_write, mac_use):\n",
        "  # We will write to main memory\n",
        "  if M*R > buffer.size(0):\n",
        "    M = math.floor(buffer.size(0)/R)\n",
        "  # Read from memory\n",
        "  for p in range(len_weights_flat, len_weights_flat+P): #0-P(sliding the inputs). Since input is stored in memory after weights\n",
        "    for m in range(0, M): #0-M Move along the depth\n",
        "        output_tensor = torch.tensor([0.])\n",
        "        rn = 0\n",
        "        for r in range(m*R, R+m*R): #0-R\n",
        "          output_tensor += main_memory[p+rn] * buffer[r] # Patial sums are writen to MAC\n",
        "          mac_use += 1 # MAC use\n",
        "          buf_read += 1 # Count buffer reads\n",
        "          mem_read += 1 # Count mem reads\n",
        "          rn += 1\n",
        "        main_memory[mem_ptr] = output_tensor # Final convolution writen to memory\n",
        "        mem_write += 1 # Count mem writes\n",
        "        mem_ptr += 1\n",
        "  return M"
      ],
      "metadata": {
        "id": "y6-QMGZd3Dyy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resourses\n",
        "main_depth =  32768\n",
        "main_width = 1 # It should be 8, but since we are using int8 data type, we make it 1\n",
        "buf_depth = 64\n",
        "buf_width = 1 # It should be 8, but since we are using int8 data type, we make it 1\n",
        "main_memory = torch.empty(main_depth, main_width)\n",
        "buffer = torch.empty(buf_depth, buf_width)\n",
        "\n",
        "mem_read  = torch.tensor(0)\n",
        "mem_write = torch.tensor(0)\n",
        "buf_read  = torch.tensor(0)\n",
        "buf_write = torch.tensor(0)\n",
        "mac_use   = torch.tensor(0)\n",
        "\n",
        "# Parameters\n",
        "M = 32\n",
        "R = 3\n",
        "P = 16\n",
        "PplusRminusOne = P + R - 1 # The input width must be P + R - 1\n",
        "\n",
        "input_tensor = torch.randint(-128, 127, (1, PplusRminusOne), dtype=torch.int8) #size(1, 4) P+R-1 = 4(len of input)\n",
        "weight_tensor = torch.randint(-128,127, (M, R), dtype=torch.int8) # (M,R) = (4,3)\n",
        "output_tensor = torch.zeros(M, P) #(M,P)=(4,2)\n",
        "\n",
        "# Flatten weight tensor into 1D\n",
        "input_flat = input_tensor.view(-1)\n",
        "weight_flat = weight_tensor.view(-1)\n",
        "output_flat = output_tensor.view(-1)\n",
        "\n",
        "# Load main memory with inputs and weights\n",
        "main_memory, mem_ptr = load_main_memory(main_memory, input_flat, weight_flat, mem_write) # Return loaded main memory and pointer to next available address in main memory\n",
        "\n",
        "# Load stationary data to buffer\n",
        "which_data = \"ws\"\n",
        "buf_row = 0 # Buffer row pointer\n",
        "frm_mem = 0\n",
        "buffer, buf_ptr = load_buffer(main_memory, buffer, buf_row, frm_mem, which_data, weight_flat.size(0), input_flat.size(0), mem_read, buf_write) # buf_ptr=Current position of last element in buffer\n",
        "\n",
        "# Perform convolution\n",
        "newM = convolution(main_memory, mem_ptr, buffer, weight_flat.size(0), M, R, P, mem_read, mem_write, buf_read, buf_write, mac_use)\n",
        "\n",
        "folds = newM*R\n",
        "while folds < R*M: # If all data did not fit in buffer, continue fitching from main memory and populating buffer in FIFO maner\n",
        "  buffer, buf_ptr = load_buffer(main_memory, buffer, buf_row, newM*R, which_data, weight_flat.size(0)-newM*R, input_flat.size(0)-newM, mem_read, buf_write)\n",
        "  newM = convolution(main_memory, mem_ptr, buffer, buf_ptr+1, int((buf_ptr+1)/R), R, P, mem_read, mem_write, buf_read, buf_write, mac_use)\n",
        "  folds += newM*R\n",
        "\n",
        "print(\"mem_read\",mem_read)\n",
        "print(\"mem_write\",mem_write)\n",
        "print(\"buf_read\",buf_read)\n",
        "print(\"buf_write\",buf_write)\n",
        "print(\"mac_use\",mac_use)\n",
        "output = main_memory[PplusRminusOne+R*M:PplusRminusOne+R*M+M*P].clone()\n",
        "print(\"Convolution output\",output.view(M,1,P))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d5-rrd03HXo",
        "outputId": "b9a20621-a9e9-4d71-da3e-eb1646895620"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mem_read tensor(1633)\n",
            "mem_write tensor(626)\n",
            "buf_read tensor(1536)\n",
            "buf_write tensor(97)\n",
            "mac_use tensor(1536)\n",
            "Convolution output tensor([[[ 1.7085e+04, -1.4400e+02, -7.7690e+03,  1.5550e+03, -1.0278e+04,\n",
            "          -8.2740e+03,  1.4280e+03,  7.5370e+03,  6.9250e+03,  4.8390e+03,\n",
            "          -4.4260e+03,  5.8760e+03, -4.1050e+03, -2.8620e+03,  1.5390e+03,\n",
            "          -2.5400e+03]],\n",
            "\n",
            "        [[ 6.3200e+02,  5.4000e+02,  2.1410e+03, -4.7700e+02, -1.9680e+03,\n",
            "          -3.5370e+03,  3.7310e+03,  5.4200e+03, -4.4690e+03, -4.7030e+03,\n",
            "          -2.3630e+03, -4.6420e+03, -3.2880e+03, -3.1290e+03,  1.0432e+04,\n",
            "           1.0350e+04]],\n",
            "\n",
            "        [[ 2.9930e+03, -2.1400e+03,  8.0180e+03,  7.8860e+03,  5.7980e+03,\n",
            "          -3.3070e+03, -9.7960e+03,  7.3560e+03,  1.1566e+04, -6.1910e+03,\n",
            "          -2.9650e+03,  1.8270e+03, -7.8020e+03,  8.5900e+02,  7.1800e+02,\n",
            "          -4.4030e+03]],\n",
            "\n",
            "        [[ 5.6530e+03,  4.8400e+03, -4.0080e+03, -8.4490e+03,  2.2040e+03,\n",
            "           2.6770e+03,  3.6000e+03, -2.0630e+03,  2.2000e+02,  5.0350e+03,\n",
            "           4.7470e+03, -4.5400e+02, -1.6580e+03,  4.5960e+03,  6.3770e+03,\n",
            "          -7.5470e+03]],\n",
            "\n",
            "        [[-6.3570e+03, -1.0540e+03, -2.7220e+03,  5.4980e+03, -3.6620e+03,\n",
            "          -7.8920e+03,  2.3700e+03, -2.4400e+02, -6.3120e+03, -9.7560e+03,\n",
            "           1.1402e+04,  1.1644e+04,  5.5560e+03, -5.0080e+03,  2.0939e+04,\n",
            "           1.1634e+04]],\n",
            "\n",
            "        [[ 4.5870e+03, -5.4860e+03, -2.0584e+04,  9.1080e+03,  1.5005e+04,\n",
            "          -1.3470e+03,  5.0940e+03,  8.2170e+03, -1.5671e+04, -1.2785e+04,\n",
            "           1.0563e+04,  6.7020e+03,  1.0969e+04,  1.6210e+04,  3.5640e+03,\n",
            "          -1.1660e+03]],\n",
            "\n",
            "        [[-2.2235e+04, -2.1896e+04, -4.0280e+03,  4.2890e+03, -2.2237e+04,\n",
            "          -1.4363e+04, -7.9820e+03,  7.4440e+03,  2.3870e+04, -1.2648e+04,\n",
            "          -2.0790e+04,  5.1580e+03, -2.1030e+03, -7.4410e+03,  2.0129e+04,\n",
            "          -1.2472e+04]],\n",
            "\n",
            "        [[-9.2830e+03,  5.4230e+03, -9.2710e+03,  5.3000e+02,  2.3520e+03,\n",
            "           8.3050e+03, -1.2620e+03, -5.9680e+03, -1.1511e+04,  1.5380e+04,\n",
            "          -1.3606e+04, -1.5394e+04, -4.7380e+03, -2.8190e+03,  8.8280e+03,\n",
            "          -7.6200e+03]],\n",
            "\n",
            "        [[-8.5220e+03,  9.7610e+03,  3.6030e+03, -7.4690e+03,  1.6756e+04,\n",
            "          -9.4820e+03, -6.8140e+03,  5.3540e+03, -8.2890e+03, -8.6000e+02,\n",
            "           2.9640e+03,  8.5620e+03, -1.8770e+03, -5.4310e+03, -9.4950e+03,\n",
            "           1.1822e+04]],\n",
            "\n",
            "        [[-1.0057e+04, -1.2878e+04, -5.0390e+03, -1.8370e+03,  7.0880e+03,\n",
            "          -7.1040e+03, -8.3970e+03,  9.5700e+03,  4.6790e+03, -5.1020e+03,\n",
            "           1.0625e+04,  1.3004e+04, -3.0650e+03, -8.6900e+02, -1.0068e+04,\n",
            "          -1.7074e+04]],\n",
            "\n",
            "        [[ 2.0760e+03,  8.1930e+03,  1.1603e+04,  1.3057e+04,  3.2760e+03,\n",
            "          -6.1440e+03,  9.1650e+03,  9.3580e+03,  4.6690e+03, -1.0100e+03,\n",
            "          -8.5680e+03,  6.5400e+03,  9.2110e+03, -6.3570e+03, -2.5180e+03,\n",
            "           3.5830e+03]],\n",
            "\n",
            "        [[ 2.2740e+03,  1.1834e+04,  5.0440e+03,  1.0470e+04, -7.4000e+01,\n",
            "          -3.1760e+03,  8.5000e+02,  1.0994e+04, -2.6760e+03, -2.0860e+03,\n",
            "           4.3400e+03,  4.5600e+02,  1.9460e+03, -4.6200e+02, -9.9140e+03,\n",
            "           2.1630e+03]],\n",
            "\n",
            "        [[-1.2036e+04,  5.2400e+03,  7.5350e+03, -1.4270e+03,  1.0351e+04,\n",
            "           9.4600e+03, -2.0750e+03, -8.1680e+03,  4.2300e+03, -6.0500e+02,\n",
            "           6.8120e+03, -4.0290e+03, -2.7110e+03, -5.8100e+02, -1.3200e+02,\n",
            "          -1.1490e+03]],\n",
            "\n",
            "        [[ 1.0899e+04,  1.9340e+03, -6.8500e+02,  4.4890e+03,  3.1710e+03,\n",
            "           8.5690e+03,  2.4620e+03, -1.8660e+03,  3.3210e+03, -9.5480e+03,\n",
            "          -1.4089e+04,  3.3790e+03,  2.7230e+03, -1.6000e+01,  6.8950e+03,\n",
            "          -1.0622e+04]],\n",
            "\n",
            "        [[-8.3460e+03,  6.0770e+03,  5.7700e+03, -2.0780e+03, -3.5340e+03,\n",
            "          -1.2452e+04, -1.1700e+02,  4.1600e+03,  1.3664e+04, -5.0340e+03,\n",
            "           1.5112e+04, -1.2908e+04, -1.5352e+04, -4.7870e+03, -1.1275e+04,\n",
            "          -3.6090e+03]],\n",
            "\n",
            "        [[ 4.2650e+03,  1.5708e+04, -5.6530e+03, -6.3730e+03, -3.5520e+03,\n",
            "           1.7955e+04,  2.3610e+03, -5.9800e+03,  1.9330e+03,  7.6560e+03,\n",
            "          -9.0020e+03, -3.3370e+03,  1.2966e+04, -4.8140e+03,  1.0952e+04,\n",
            "           1.9260e+03]],\n",
            "\n",
            "        [[-2.3080e+03, -1.3554e+04, -2.1322e+04, -3.6520e+03,  3.9760e+03,\n",
            "           1.7802e+04,  1.3442e+04,  1.2138e+04, -4.0540e+03, -4.1880e+03,\n",
            "           1.0444e+04,  1.5342e+04, -7.3220e+03, -1.7140e+03,  9.9980e+03,\n",
            "          -1.1940e+03]],\n",
            "\n",
            "        [[ 1.2760e+03,  8.5780e+03, -1.2282e+04,  1.1636e+04, -7.9420e+03,\n",
            "           5.0760e+03, -2.4420e+03, -1.5526e+04,  4.4440e+03,  7.0280e+03,\n",
            "           1.2086e+04,  2.0460e+03,  1.3354e+04, -6.0200e+02, -2.4400e+02,\n",
            "          -4.2800e+02]],\n",
            "\n",
            "        [[ 1.0786e+04, -3.4260e+03, -2.2820e+03,  4.4540e+03,  5.5580e+03,\n",
            "           2.9680e+03, -2.6860e+03, -1.2026e+04,  2.7080e+03, -1.4582e+04,\n",
            "           8.7080e+03,  1.2046e+04,  2.0380e+03,  1.2056e+04,  8.1440e+03,\n",
            "          -4.2540e+03]],\n",
            "\n",
            "        [[-1.2642e+04,  4.4060e+03,  2.0900e+03,  6.6680e+03, -1.0136e+04,\n",
            "          -3.8900e+03,  2.1820e+03, -6.7800e+02, -4.2580e+03,  1.1494e+04,\n",
            "           2.5640e+03, -7.3400e+03,  3.6280e+03, -3.4330e+03,  2.2460e+03,\n",
            "           3.6440e+03]],\n",
            "\n",
            "        [[ 7.2770e+03,  1.3059e+04, -2.2330e+03, -9.2280e+03, -7.6410e+03,\n",
            "          -6.7940e+03, -5.6840e+03,  6.3170e+03, -3.2240e+03, -1.1381e+04,\n",
            "          -4.7770e+03,  7.3450e+03, -4.1000e+02, -7.6630e+03, -5.2390e+03,\n",
            "          -4.1400e+02]],\n",
            "\n",
            "        [[-4.0478e-34,  4.5579e-41, -4.0478e-34,  4.5579e-41, -9.2400e-25,\n",
            "           4.5577e-41, -2.4582e-24,  4.5577e-41, -3.8066e-34,  4.5579e-41,\n",
            "          -2.4582e-24,  4.5577e-41, -2.4582e-24,  4.5577e-41, -4.2584e-35,\n",
            "           4.5579e-41]],\n",
            "\n",
            "        [[-3.7235e-34,  4.5579e-41, -4.6962e-35,  4.5579e-41, -3.7235e-34,\n",
            "           4.5579e-41, -3.7235e-34,  4.5579e-41, -3.7235e-34,  4.5579e-41,\n",
            "          -2.1970e-39,  4.5579e-41, -3.7394e-34,  4.5579e-41, -3.4517e-34,\n",
            "           4.5579e-41]],\n",
            "\n",
            "        [[-3.7394e-34,  4.5579e-41, -4.4353e-34,  4.5579e-41, -4.0476e-34,\n",
            "           4.5579e-41, -8.1220e-25,  4.5577e-41, -4.0476e-34,  4.5579e-41,\n",
            "          -9.2358e-25,  4.5577e-41,  6.5558e+10,  4.5579e-41, -3.8066e-34,\n",
            "           4.5579e-41]],\n",
            "\n",
            "        [[ 6.5558e+10,  4.5579e-41,  6.5558e+10,  4.5579e-41, -9.2337e-25,\n",
            "           4.5577e-41,  1.8037e+28,  4.5579e-41, -3.3779e-34,  4.5579e-41,\n",
            "          -9.2345e-25,  4.5577e-41, -2.4507e-34,  4.5579e-41, -3.8042e-34,\n",
            "           4.5579e-41]],\n",
            "\n",
            "        [[-3.4517e-34,  4.5579e-41, -9.2275e-25,  4.5577e-41, -4.0494e-34,\n",
            "           4.5579e-41, -3.7524e-34,  4.5579e-41, -4.0494e-34,  4.5579e-41,\n",
            "          -9.2353e-25,  4.5577e-41, -4.0494e-34,  4.5579e-41, -3.7524e-34,\n",
            "           4.5579e-41]],\n",
            "\n",
            "        [[-4.0494e-34,  4.5579e-41, -3.8042e-34,  4.5579e-41, -4.4353e-34,\n",
            "           4.5579e-41, -4.0476e-34,  4.5579e-41, -3.7524e-34,  4.5579e-41,\n",
            "          -4.0476e-34,  4.5579e-41, -9.2277e-25,  4.5577e-41, -2.4582e-24,\n",
            "           4.5577e-41]],\n",
            "\n",
            "        [[-3.8049e-34,  4.5579e-41, -2.4582e-24,  4.5577e-41, -2.4582e-24,\n",
            "           4.5577e-41, -3.7524e-34,  4.5579e-41, -2.4582e-24,  4.5577e-41,\n",
            "          -9.2329e-25,  4.5577e-41, -1.3268e-34,  4.5579e-41, -3.8066e-34,\n",
            "           4.5579e-41]],\n",
            "\n",
            "        [[-1.3268e-34,  4.5579e-41, -1.3268e-34,  4.5579e-41, -1.3268e-34,\n",
            "           4.5579e-41, -9.2267e-25,  4.5577e-41,  1.8037e+28,  4.5579e-41,\n",
            "          -3.3779e-34,  4.5579e-41, -9.2346e-25,  4.5577e-41, -1.7915e-35,\n",
            "           4.5579e-41]],\n",
            "\n",
            "        [[-3.8049e-34,  4.5579e-41,  1.8037e+28,  4.5579e-41, -1.3268e-34,\n",
            "           4.5579e-41, -8.1209e-25,  4.5577e-41,  1.8037e+28,  4.5579e-41,\n",
            "           1.8037e+28,  4.5579e-41,  1.8037e+28,  4.5579e-41, -2.4507e-34,\n",
            "           4.5579e-41]],\n",
            "\n",
            "        [[ 1.8037e+28,  4.5579e-41, -9.2264e-25,  4.5577e-41, -2.4586e-24,\n",
            "           4.5577e-41, -3.8066e-34,  4.5579e-41, -2.4586e-24,  4.5577e-41,\n",
            "          -2.4586e-24,  4.5577e-41, -2.4813e-24,  4.5577e-41,  1.8037e+28,\n",
            "           4.5579e-41]],\n",
            "\n",
            "        [[-3.3779e-34,  4.5579e-41, -2.4809e-24,  4.5577e-41, -2.4507e-34,\n",
            "           4.5579e-41, -3.8042e-34,  4.5579e-41, -3.4517e-34,  4.5579e-41,\n",
            "          -2.4810e-24,  4.5577e-41, -4.0494e-34,  4.5579e-41, -3.7524e-34,\n",
            "           4.5579e-41]]])\n"
          ]
        }
      ]
    }
  ]
}
